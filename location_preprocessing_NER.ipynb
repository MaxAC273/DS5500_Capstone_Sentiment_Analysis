{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c792209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         hashed_userid masked_username         location  \\\n",
      "0      415371  19868647935216335990       *****ecot              NaN   \n",
      "1      415370  95273352056344375133       *****kh59  Terre Haute, IN   \n",
      "2      415369  42256911176251501556  *******eDuster         Chi-town   \n",
      "3      415368  98949018742144878760       *****ll42              NaN   \n",
      "4      415367  83242079331442835051  *******tresist              NaN   \n",
      "\n",
      "   following  followers  totaltweets usercreateddt              tweetid  \\\n",
      "0       1109        796       189199       9/16/09  1560823411047268352   \n",
      "1        854        298        16999      10/10/17  1560823347583361024   \n",
      "2        416       8852        11699       3/26/09  1560823151671488513   \n",
      "3        603        179        59766       3/14/14  1560822898780213249   \n",
      "4        257        758       272531       2/16/17  1560822761706094592   \n",
      "\n",
      "  tweetcreatedts  ...                                           hashtags  \\\n",
      "0        57:54.0  ...  [{'text': 'MyBodyMyChoice', 'indices': [200, 2...   \n",
      "1        57:39.0  ...  [{'text': 'mybodymychoice', 'indices': [55, 70...   \n",
      "2        56:52.0  ...  [{'text': 'OnThisDay', 'indices': [32, 42]}, {...   \n",
      "3        55:52.0  ...  [{'text': 'NY', 'indices': [24, 27]}, {'text':...   \n",
      "4        55:19.0  ...     [{'text': 'WomensRights', 'indices': [0, 13]}]   \n",
      "\n",
      "  language favorite_count is_retweet    original_tweet_id  \\\n",
      "0       en              0       True  1560766115776565248   \n",
      "1       en              0      False                    0   \n",
      "2       en              0       True  1560280488488718336   \n",
      "3       en              0       True  1560750229720563712   \n",
      "4       en              0       True  1560794896663203840   \n",
      "\n",
      "   in_reply_to_status_id  is_quote_status  quoted_status_id  extractedts  \\\n",
      "0                      0            False                 0      58:51.1   \n",
      "1    1560769551347900416            False                 0      58:51.1   \n",
      "2                      0            False                 0      58:51.1   \n",
      "3                      0            False                 0      58:51.1   \n",
      "4                      0            False                 0      58:51.1   \n",
      "\n",
      "   cleaned_location  \n",
      "0              None  \n",
      "1   terre haute, in  \n",
      "2          chi-town  \n",
      "3              None  \n",
      "4              None  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example: Loading a DataFrame with Twitter data\n",
    "# Replace this with your actual data loading code\n",
    "# Ensure you have a column named 'location' in your DataFrame\n",
    "df = pd.read_csv('twitter_data.csv')\n",
    "\n",
    "# Function to clean and standardize location data\n",
    "def clean_location(location):\n",
    "    if pd.isnull(location) or location.strip() == '':\n",
    "        return None  # Handle missing or empty locations\n",
    "    location = location.strip().lower()  # Standardize: trim spaces and convert to lowercase\n",
    "    \n",
    "    # Handle specific known variations\n",
    "    # Expand this dictionary based on your dataset\n",
    "    location_corrections = {\n",
    "        #'nyc': 'new york city',\n",
    "        #'sf': 'san francisco',\n",
    "        # Add more corrections as needed\n",
    "    }\n",
    "\n",
    "    return location_corrections.get(location, location)\n",
    "\n",
    "# Apply the cleaning function to the location column\n",
    "df['cleaned_location'] = df['location'].apply(clean_location)\n",
    "\n",
    "# Optionally, drop rows where location is None if you don't need them\n",
    "# df = df.dropna(subset=['cleaned_location'])\n",
    "\n",
    "# Inspect the cleaned DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c48d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         hashed_userid masked_username         location  \\\n",
      "0      415371  19868647935216335990       *****ecot              NaN   \n",
      "1      415370  95273352056344375133       *****kh59  Terre Haute, IN   \n",
      "2      415369  42256911176251501556  *******eDuster         Chi-town   \n",
      "3      415368  98949018742144878760       *****ll42              NaN   \n",
      "4      415367  83242079331442835051  *******tresist              NaN   \n",
      "\n",
      "   following  followers  totaltweets usercreateddt              tweetid  \\\n",
      "0       1109        796       189199       9/16/09  1560823411047268352   \n",
      "1        854        298        16999      10/10/17  1560823347583361024   \n",
      "2        416       8852        11699       3/26/09  1560823151671488513   \n",
      "3        603        179        59766       3/14/14  1560822898780213249   \n",
      "4        257        758       272531       2/16/17  1560822761706094592   \n",
      "\n",
      "  tweetcreatedts  ...  language favorite_count is_retweet  \\\n",
      "0        57:54.0  ...        en              0       True   \n",
      "1        57:39.0  ...        en              0      False   \n",
      "2        56:52.0  ...        en              0       True   \n",
      "3        55:52.0  ...        en              0       True   \n",
      "4        55:19.0  ...        en              0       True   \n",
      "\n",
      "     original_tweet_id  in_reply_to_status_id  is_quote_status  \\\n",
      "0  1560766115776565248                      0            False   \n",
      "1                    0    1560769551347900416            False   \n",
      "2  1560280488488718336                      0            False   \n",
      "3  1560750229720563712                      0            False   \n",
      "4  1560794896663203840                      0            False   \n",
      "\n",
      "   quoted_status_id  extractedts  cleaned_location  extracted_locations  \n",
      "0                 0      58:51.1              None                  NaN  \n",
      "1                 0      58:51.1   terre haute, in        [Terre Haute]  \n",
      "2                 0      58:51.1          chi-town                   []  \n",
      "3                 0      58:51.1              None                  NaN  \n",
      "4                 0      58:51.1              None                  NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_lg\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English language model\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Function to extract locations using spaCy's NER\n",
    "def extract_locations(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
    "\n",
    "# Function to clean and standardize location data\n",
    "def clean_location(location):\n",
    "    if pd.isnull(location) or location.strip() == '':\n",
    "        return None  # Handle missing or empty locations\n",
    "    location = location.strip().lower()  # Standardize: trim spaces and convert to lowercase\n",
    "\n",
    "    # Here, you can also integrate spaCy's NER results if needed\n",
    "    # For example, using extract_locations(location) to further process the location\n",
    "\n",
    "    # Handle specific known variations\n",
    "    location_corrections = {\n",
    "        # Add your corrections here\n",
    "    }\n",
    "\n",
    "    return location_corrections.get(location, location)\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('twitter_data.csv')\n",
    "\n",
    "# Apply the cleaning function to the location column\n",
    "df['cleaned_location'] = df['location'].apply(clean_location)\n",
    "\n",
    "# New: Extract locations using NER and add to a new column\n",
    "df['extracted_locations'] = df['location'].apply(lambda x: extract_locations(x) if pd.notnull(x) else x)\n",
    "\n",
    "# Optionally, drop rows where location is None if you don't need them\n",
    "# df = df.dropna(subset=['cleaned_location'])\n",
    "\n",
    "# Inspect the cleaned DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08ea26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         hashed_userid masked_username         location  \\\n",
      "0      415371  19868647935216335990       *****ecot              NaN   \n",
      "1      415370  95273352056344375133       *****kh59  Terre Haute, IN   \n",
      "2      415369  42256911176251501556  *******eDuster         Chi-town   \n",
      "3      415368  98949018742144878760       *****ll42              NaN   \n",
      "4      415367  83242079331442835051  *******tresist              NaN   \n",
      "\n",
      "   following  followers  totaltweets usercreateddt              tweetid  \\\n",
      "0       1109        796       189199       9/16/09  1560823411047268352   \n",
      "1        854        298        16999      10/10/17  1560823347583361024   \n",
      "2        416       8852        11699       3/26/09  1560823151671488513   \n",
      "3        603        179        59766       3/14/14  1560822898780213249   \n",
      "4        257        758       272531       2/16/17  1560822761706094592   \n",
      "\n",
      "  tweetcreatedts  ...  language favorite_count is_retweet  \\\n",
      "0        57:54.0  ...        en              0       True   \n",
      "1        57:39.0  ...        en              0      False   \n",
      "2        56:52.0  ...        en              0       True   \n",
      "3        55:52.0  ...        en              0       True   \n",
      "4        55:19.0  ...        en              0       True   \n",
      "\n",
      "     original_tweet_id  in_reply_to_status_id  is_quote_status  \\\n",
      "0  1560766115776565248                      0            False   \n",
      "1                    0    1560769551347900416            False   \n",
      "2  1560280488488718336                      0            False   \n",
      "3  1560750229720563712                      0            False   \n",
      "4  1560794896663203840                      0            False   \n",
      "\n",
      "   quoted_status_id  extractedts  cleaned_location  extracted_locations  \n",
      "0                 0      58:51.1              None                  NaN  \n",
      "1                 0      58:51.1   terre haute, in        [Terre Haute]  \n",
      "2                 0      58:51.1          chi-town                 None  \n",
      "3                 0      58:51.1              None                  NaN  \n",
      "4                 0      58:51.1              None                  NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to replace empty lists with None\n",
    "def remove_empty_lists(location_list):\n",
    "    if location_list:  # This will be False for empty lists\n",
    "        return location_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['extracted_locations'] = df['extracted_locations'].apply(remove_empty_lists)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a86cfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "370279b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "none_count = df['extracted_locations'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6576713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140531\n"
     ]
    }
   ],
   "source": [
    "print(none_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a90d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8695966f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
